apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: spark
    part: spark-historyserver
  name: spark-historyserver
spec:
  replicas: 1
  selector:
    matchLabels:
      part: spark-historyserver
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        part: spark-historyserver
    spec:
      containers:
        - args:
            - bash
            - -c
            - /opt/spark/sbin/start-history-server.sh --properties-file /opt/spark/conf/spark-defaults.conf
          env:
            - name: SPARK_DAEMON_MEMORY
              value: 1G
            - name: SPARK_NO_DAEMONIZE
              value: "true"
            - name: SPARK_SCALA_VERSION
              value: "2.13"
            #- name: SPARK_HISTORY_OPTS_EVENTLOG_DIR
            # value: "hdfs://hdfs-namenode-0.hdfs-namenode-service:9000/app/spark/spark-events"
            #- name: SPARK_HISTORY_FS_LOGDIRECTORY
            # value: "hdfs://hdfs-namenode-0.hdfs-namenode-service:9000/app/spark/spark-events"
          image: mataelang/spark:3.3.1-scala2.13
          name: spark-historyserver
          securityContext:
            runAsUser: 0
          ports:
            - containerPort: 18080
          resources:
            limits:
              cpu: "1"
              memory: "1Gi"
            requests:
              cpu: "100m"
              memory: "1Gi"
          volumeMounts:
            - name: spark-config
              mountPath: /opt/spark/conf/
              #readOnly: true
      restartPolicy: Always
      volumes:
        - name: spark-config
          configMap:
            name: spark-config
            # items:
            #  - key: spark-defaults.conf
            #   path: spark-defaults.conf
