apiVersion: v1
kind: Pod
metadata:
  labels:
    app: spark
    part: spark-submit
  name: spark-submit-aggr
spec:
  containers:
    - args:
        - bash
        - -c
        - "/opt/spark/bin/spark-submit
          --class $SPARK_APP_CLASSNAME --name $SPARK_APP_NAME
          --total-executor-cores $TOTAL_EXECUTOR_CORES --conf spark.ui.port=$SPARK_APP_UI
          --conf spark.submit.deployMode=$DEPLOY_MODE --conf spark.driver.memory=$SPARK_DRIVER_MEMORY
          --conf spark.executor.cores=$SPARK_EXECUTOR_CORES --conf spark.executor.memory=$SPARK_EXECUTOR_MEMORY
          --conf spark.eventLog.dir=$SPARK_EVENTLOG_DIR --conf spark.sql.shuffle.partitions=$SPARK_SHUFFLE_PARTITION
          --conf spark.sql.codegen.aggregate.map.twolevel.enabled=false --conf spark.sql.streaming.metricsEnabled=true
          --files local:///opt/spark/conf/app.properties $SPARK_APP_JAR_PATH"
      env:
        - name: DEPLOY_MODE
          value: cluster
        - name: HADOOP_USER_NAME
          valueFrom:
            configMapKeyRef:
              key: HADOOP_USER_NAME
              name: spark-env
        - name: SPARK_APP_CLASSNAME
          value: org.mataelang.kaspacore.jobs.SensorAggregationStreamJob
        - name: SPARK_APP_JAR_PATH
          valueFrom:
            configMapKeyRef:
              key: SPARK_APP_JAR_PATH
              name: spark-env
        - name: SPARK_APP_NAME
          value: SensorAggregationStreamJob
        - name: SPARK_APP_UI
          value: "4041"
        - name: SPARK_DRIVER_MEMORY
          value: 2g
        - name: SPARK_EVENTLOG_DIR
          valueFrom:
            configMapKeyRef:
              key: SPARK_EVENTLOG_DIR
              name: spark-env
        - name: SPARK_EXECUTOR_CORES
          value: "1"
        - name: SPARK_EXECUTOR_MEMORY
          value: 2g
        - name: SPARK_HISTORY_OPTS
          valueFrom:
            configMapKeyRef:
              key: SPARK_HISTORY_OPTS
              name: spark-env
        - name: SPARK_MASTER_HOST
          value: spark://spark-master-service.default.svc.cluster.local:7077
        - name: SPARK_MASTER_PORT
          value: "7077"
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        - name: SPARK_SCALA_VERSION
          value: "2.13"
        - name: SPARK_SHUFFLE_PARTITION
          value: "1"
        - name: TOTAL_EXECUTOR_CORES
          value: "1"
      image: mataelang/spark:3.3.1-scala2.13
      name: spark-submit-aggr
      resources: {}
      volumeMounts:
        - name: spark-conf
          mountPath: /opt/spark/conf/
          readOnly: true
      securityContext:
        runAsUser: 0
      workingDir: /opt/spark
  restartPolicy: Never
  volumes:
    - name: spark-conf
      configMap:
        name: spark-conf
