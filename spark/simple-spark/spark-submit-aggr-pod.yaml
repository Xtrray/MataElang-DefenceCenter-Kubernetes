apiVersion: v1
kind: Pod
metadata:
  labels:
    app: spark
    part: spark-submit-aggr
  name: spark-submit-aggr
spec:
  containers:
    - args:
        - bash
        - -c
        - "/opt/spark/bin/spark-submit --class $()$(SPARK)_APP_CLASSNAME
          --name $()$(SPARK)_APP_NAME --total-executor-cores $()$(TOTAL)_EXECUTOR_CORES
          --conf spark.ui.port=$()$(SPARK)_APP_UI --conf spark.submit.deployMode=$()$(DEPLOY)_MODE
          --conf spark.driver.memory=$()$(SPARK)_DRIVER_MEMORY --conf spark.executor.cores=$()$(SPARK)_EXECUTOR_CORES
          --conf spark.executor.memory=$()$(SPARK)_EXECUTOR_MEMORY --conf spark.eventLog.dir=$()$(SPARK)_EVENTLOG_DIR
          --conf spark.sql.shuffle.partitions=$()$(SPARK)_SHUFFLE_PARTITION --conf spark.sql.codegen.aggregate.map.twolevel.enabled=false
          --conf spark.sql.streaming.metricsEnabled=true --files conf/app.properties $()$(SPARK)_APP_JAR_PATH"
      env:
        - name: DEPLOY_MODE
          value: cluster
        - name: SPARK_APP_CLASSNAME
          value: org.mataelang.kaspacore.jobs.SensorAggregationStreamJob
        - name: SPARK_APP_NAME
          value: SensorAggregationStreamJob
        - name: SPARK_APP_UI
          value: "4041"
        - name: SPARK_DRIVER_MEMORY
          value: 2g
        - name: SPARK_EXECUTOR_CORES
          value: "1"
        - name: SPARK_EXECUTOR_MEMORY
          value: 2g
        - name: SPARK_MASTER_HOST
          value: spark-master-0.spark-master-service
        - name: SPARK_MASTER_PORT
          value: "7077"
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        - name: SPARK_SCALA_VERSION
          value: "2.13"
        - name: SPARK_SHUFFLE_PARTITION
          value: "1"
        - name: TOTAL_EXECUTOR_CORES
          value: "1"
      image: mataelang/spark:3.3.1-scala2.13
      name: spark-submit-aggr
      ports:
        - containerPort: 7778
      #resources: {}
      volumeMounts:
        - name: spark-config
          mountPath: /opt/spark/conf/
          subPath: conf
      workingDir: /opt/spark
  restartPolicy: Never
  volumes:
    - name: spark-config
      configMap:
        name: spark-config
